{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle HF Trainer: full fine-tuning on GLUE using Hugging Face task-specific head\n# Default: bert-base-uncased with AutoModelForSequenceClassification (no manual head)\n# Run in a Kaggle notebook cell. Turn Internet and GPU on.\n\n!pip -q install \"transformers>=4.43\" \"datasets>=2.20\" \"evaluate>=0.4\" \"accelerate>=0.33\" scikit-learn wandb -U\n\nimport os\nimport json\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\n\nimport numpy as np\nimport torch\n\nfrom datasets import load_dataset\nimport evaluate\n\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)\n\n# ---------------------------------\n# Config\n# ---------------------------------\n@dataclass\nclass RunConfig:\n    task_name: str = \"sst2\"              # cola sst2 mrpc qqp stsb mnli qnli rte wnli\n    model_name: str = \"bert-base-uncased\" # any compatible encoder model\n    output_dir: str = \"/kaggle/working/glue_ft\"\n    num_train_epochs: float = 3.0\n    per_device_train_batch_size: int = 32\n    per_device_eval_batch_size: int = 64\n    learning_rate: float = 2e-5\n    weight_decay: float = 0.01\n    warmup_ratio: float = 0.06\n    seed: int = 42\n    save_strategy: str = \"epoch\"         # or \"steps\"\n    eval_strategy: str = \"epoch\"         # or \"steps\"\n    save_total_limit: int = 2\n    fp16: bool = True                     # set False on CPU\n    bf16: bool = False                    # set True on A100/Hopper if desired\n    # W&B settings\n    wandb_enable: bool = True\n    wandb_project: Optional[str] = \"glue-ft\"\n    wandb_entity: Optional[str] = None\n    wandb_run_name: Optional[str] = None\n    wandb_offline_fallback: bool = True\n\nCFG = RunConfig()\n\nGLUE_SENTENCE_KEYS = {\n    \"cola\": (\"sentence\", None),\n    \"sst2\": (\"sentence\", None),\n    \"mrpc\": (\"sentence1\", \"sentence2\"),\n    \"qqp\": (\"question1\", \"question2\"),\n    \"stsb\": (\"sentence1\", \"sentence2\"),\n    \"mnli\": (\"premise\", \"hypothesis\"),\n    \"qnli\": (\"question\", \"sentence\"),\n    \"rte\": (\"sentence1\", \"sentence2\"),\n    \"wnli\": (\"sentence1\", \"sentence2\"),\n}\n\ndef is_regression_task(task: str) -> bool:\n    return task.lower() == \"stsb\"\n\n# ---------------------------------\n# Weights & Biases setup\n# ---------------------------------\n\ndef setup_wandb(cfg: RunConfig, task: str) -> str:\n    \"\"\"Login and init W&B. Uses Kaggle Secrets if available or env WANDB_API_KEY.\n    Falls back to offline if no key and offline fallback is True.\n    Returns a run_name string.\"\"\"\n    import wandb\n\n    run_name = cfg.wandb_run_name or f\"{task}-{cfg.model_name}-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}\"\n\n    # Try environment variable or Kaggle Secrets\n    key = os.environ.get(\"WANDB_API_KEY\")\n    if key is None:\n        try:\n            from kaggle_secrets import UserSecretsClient\n            key = UserSecretsClient().get_secret(\"WANDB_API_KEY\")\n        except Exception:\n            key = None\n\n    if key:\n        wandb.login(key=key)\n    elif cfg.wandb_offline_fallback:\n        os.environ[\"WANDB_MODE\"] = \"offline\"\n\n    wandb.init(\n        project=cfg.wandb_project,\n        entity=cfg.wandb_entity,\n        name=run_name,\n        config={k: v for k, v in vars(cfg).items() if \"wandb\" not in k},\n    )\n    return run_name\n\n# ---------------------------------\n# Main\n# ---------------------------------\n\ndef main(cfg: RunConfig):\n    os.makedirs(cfg.output_dir, exist_ok=True)\n    set_seed(cfg.seed)\n\n    task = cfg.task_name.lower()\n    if task not in GLUE_SENTENCE_KEYS:\n        raise ValueError(f\"Unknown GLUE task: {task}\")\n\n    # ---------------- Data ----------------\n    raw = load_dataset(\"glue\", task)\n\n    if is_regression_task(task):\n        num_labels = 1\n        label_list = None\n    else:\n        label_list = raw[\"train\"].features[\"label\"].names\n        num_labels = len(label_list)\n\n    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, use_fast=True)\n\n    sent1_key, sent2_key = GLUE_SENTENCE_KEYS[task]\n\n    def preprocess(batch):\n        if sent2_key is None:\n            tokenized = tokenizer(batch[sent1_key], truncation=True)\n        else:\n            tokenized = tokenizer(batch[sent1_key], batch[sent2_key], truncation=True)\n        if \"label\" in batch:\n            tokenized[\"labels\"] = batch[\"label\"]\n        return tokenized\n\n    encoded = raw.map(preprocess, batched=True, remove_columns=raw[\"train\"].column_names)\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    # ---------------- Metrics ----------------\n    metric = evaluate.load(\"glue\", task)\n\n    def compute_metrics(eval_pred):\n        preds, labels = eval_pred\n        if is_regression_task(task):\n            preds = np.squeeze(preds)\n            res = metric.compute(predictions=preds, references=labels)\n            # avg Pearson + Spearman as an extra combined score\n            res[\"combined_score\"] = float((res.get(\"pearson\", 0.0) + res.get(\"spearmanr\", 0.0)) / 2.0)\n            return res\n        else:\n            preds = np.argmax(preds, axis=1)\n            res = metric.compute(predictions=preds, references=labels)\n            if task in {\"mrpc\", \"qqp\"}:\n                res[\"combined_score\"] = float((res.get(\"f1\", 0.0) + res.get(\"accuracy\", 0.0)) / 2.0)\n            return res\n\n    if task == \"cola\":\n        best_metric = \"matthews_correlation\"\n    elif task == \"stsb\":\n        best_metric = \"combined_score\"\n    elif task in {\"mrpc\", \"qqp\"}:\n        best_metric = \"f1\"\n    else:\n        best_metric = \"accuracy\"\n\n    # ---------------- Model (HF-native) ----------------\n    # Full finetuning via AutoModelForSequenceClassification (no custom head code)\n    config = AutoConfig.from_pretrained(cfg.model_name, num_labels=num_labels)\n    if is_regression_task(task):\n        config.problem_type = \"regression\"  # ensures MSE loss and float outputs\n    model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name, config=config)\n\n    # ---------------- Splits ----------------\n    train_ds = encoded[\"train\"]\n    if task == \"mnli\":\n        eval_ds = encoded[\"validation_matched\"]\n        eval_mm_ds = encoded[\"validation_mismatched\"]\n    else:\n        eval_ds = encoded[\"validation\"]\n        eval_mm_ds = None\n\n    # ---------------- Trainer ----------------\n    if cfg.wandb_enable:\n        run_name = setup_wandb(cfg, task)\n        report_targets = [\"wandb\"]\n    else:\n        run_name = f\"{task}-{cfg.model_name}\"\n        report_targets = [\"none\"]\n\n    args = TrainingArguments(\n        output_dir=cfg.output_dir,\n        learning_rate=cfg.learning_rate,\n        per_device_train_batch_size=cfg.per_device_train_batch_size,\n        per_device_eval_batch_size=cfg.per_device_eval_batch_size,\n        num_train_epochs=cfg.num_train_epochs,\n        weight_decay=cfg.weight_decay,\n        warmup_ratio=cfg.warmup_ratio,\n        eval_strategy=cfg.eval_strategy,\n        save_strategy=cfg.save_strategy,\n        save_total_limit=cfg.save_total_limit,\n        load_best_model_at_end=True,\n        metric_for_best_model=best_metric,\n        greater_is_better=True,\n        fp16=cfg.fp16 and torch.cuda.is_available(),\n        bf16=cfg.bf16 and torch.cuda.is_available(),\n        logging_steps=50,\n        report_to=report_targets,\n        run_name=run_name,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=eval_ds,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    # ---------------- Train ----------------\n    trainer.train()\n\n    # Log a small marker so the run has a final step in W&B\n    try:\n        if cfg.wandb_enable:\n            import wandb\n            wandb.log({\"final/global_step\": trainer.state.global_step})\n    except Exception:\n        pass\n\n    # Save best model for later evaluation / reuse\n    best_dir = os.path.join(cfg.output_dir, \"best_model\")\n    os.makedirs(best_dir, exist_ok=True)\n    trainer.save_model(best_dir)          # saves config + model weights\n    tokenizer.save_pretrained(best_dir)\n\n    # ---------------- Evaluate ----------------\n    val_metrics = trainer.evaluate(eval_dataset=eval_ds)\n    print(\"Validation:\", val_metrics)\n\n    if cfg.wandb_enable:\n        try:\n            import wandb\n            wandb.log({f\"val/{k}\": v for k, v in val_metrics.items()})\n        except Exception:\n            pass\n\n    if eval_mm_ds is not None:\n        mm_metrics = trainer.evaluate(eval_dataset=eval_mm_ds)\n        print(\"Validation mismatched:\", mm_metrics)\n        if cfg.wandb_enable:\n            try:\n                import wandb\n                wandb.log({f\"val_mm/{k}\": v for k, v in mm_metrics.items()})\n            except Exception:\n                pass\n\n    with open(os.path.join(cfg.output_dir, \"val_metrics.json\"), \"w\") as f:\n        json.dump(val_metrics, f, indent=2)\n    if eval_mm_ds is not None:\n        with open(os.path.join(cfg.output_dir, \"val_mm_metrics.json\"), \"w\") as f:\n            json.dump(mm_metrics, f, indent=2)\n\n    # Optionally dump logits for later analysis\n    def dump_preds(ds, name):\n        preds = trainer.predict(ds)\n        np.save(os.path.join(cfg.output_dir, f\"{name}_logits.npy\"), preds.predictions)\n        np.save(os.path.join(cfg.output_dir, f\"{name}_labels.npy\"), preds.label_ids)\n\n    dump_preds(eval_ds, \"val\")\n    if eval_mm_ds is not None:\n        dump_preds(eval_mm_ds, \"val_mismatched\")\n\n    if \"test\" in encoded:\n        test_ds = encoded[\"test\"]\n    # Ensure no label columns exist to avoid CrossEntropy on invalid targets\n    for col in (\"label\", \"labels\"):\n        if col in test_ds.column_names:\n            test_ds = test_ds.remove_columns(col)\n    try:\n        test_preds = trainer.predict(test_ds, metric_key_prefix=\"test\").predictions\n        np.save(os.path.join(cfg.output_dir, \"test_logits.npy\"), test_preds)\n    except Exception as e:\n        print(\"[WARN] Skipping test prediction due to:\", e)\n    \n    print(\"Saved best model to:\", best_dir)\n\n    # W&B finish\n    try:\n        if cfg.wandb_enable:\n            import wandb\n            wandb.finish()\n    except Exception:\n        pass\n\n# ---------------------------------\n# Helper: reload a saved checkpoint and evaluate (HF-native)\n# ---------------------------------\n\ndef load_for_eval(checkpoint_dir: str, task: str):\n    task = task.lower()\n    raw = load_dataset(\"glue\", task)\n\n    is_reg = is_regression_task(task)\n    if is_reg:\n        num_labels = 1\n    else:\n        num_labels = len(raw[\"train\"].features[\"label\"].names)\n\n    tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir, use_fast=True)\n\n    sent1_key, sent2_key = GLUE_SENTENCE_KEYS[task]\n\n    def preprocess(batch):\n        if sent2_key is None:\n            tokenized = tokenizer(batch[sent1_key], truncation=True)\n        else:\n            tokenized = tokenizer(batch[sent1_key], batch[sent2_key], truncation=True)\n        if \"label\" in batch:\n            tokenized[\"labels\"] = batch[\"label\"]\n        return tokenized\n\n    encoded = raw.map(preprocess, batched=True, remove_columns=raw[\"train\"].column_names)\n    eval_ds = encoded[\"validation_matched\"] if task == \"mnli\" else encoded[\"validation\"]\n\n    # load the exact model back (config carries num_labels and problem type)\n    model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir)\n\n    metric = evaluate.load(\"glue\", task)\n\n    def compute_metrics(eval_pred):\n        preds, labels = eval_pred\n        if is_reg:\n            preds = np.squeeze(preds)\n            res = metric.compute(predictions=preds, references=labels)\n            res[\"combined_score\"] = float((res.get(\"pearson\", 0.0) + res.get(\"spearmanr\", 0.0)) / 2.0)\n            return res\n        preds = np.argmax(preds, axis=1)\n        res = metric.compute(predictions=preds, references=labels)\n        if task in {\"mrpc\", \"qqp\"}:\n            res[\"combined_score\"] = float((res.get(\"f1\", 0.0) + res.get(\"accuracy\", 0.0)) / 2.0)\n        return res\n\n    collator = DataCollatorWithPadding(tokenizer)\n    args = TrainingArguments(output_dir=os.path.join(checkpoint_dir, \"eval_tmp\"), per_device_eval_batch_size=64, report_to=[\"none\"]) \n    trainer = Trainer(model=model, args=args, eval_dataset=eval_ds, tokenizer=tokenizer, data_collator=collator, compute_metrics=compute_metrics)\n    metrics = trainer.evaluate()\n    print(\"Reloaded checkpoint metrics:\", metrics)\n    return metrics\n\n\nif __name__ == \"__main__\":\n    main(CFG)\n\n\"\"\"\nQuick how to on Kaggle\n\n1. Keep Internet and GPU on.\n2. To use W&B, add your key via Kaggle Secrets: Workspace > Add-ons > Secrets > Create new secret with key WANDB_API_KEY. Or set it in an env var.\n3. Run this cell. Default model is bert-base-uncased with AutoModelForSequenceClassification.\n4. Artifacts:\n   - best model at /kaggle/working/glue_ft/best_model\n   - JSON metrics in the output dir\n   - optional logits .npy files for validation and test\n5. Later evaluation:\n\nfrom Kaggle_HF_Trainer_GLUE_full_finetune import load_for_eval\nload_for_eval(\"/kaggle/working/glue_ft/best_model\", \"sst2\")\n\nW&B tips\n- Set CFG.wandb_enable = True to log. Set False to disable.\n- Project and entity are configurable: CFG.wandb_project, CFG.wandb_entity.\n- If no key is found and offline fallback is True, the run will log locally in offline mode.\n\nNotes\n- This is full finetuning. Nothing is frozen.\n- For STS-B, config.problem_type=\"regression\" is set and MSE is used automatically.\n- To switch models, set CFG.model_name (for example, roberta-base).\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-01T10:04:55.964760Z","iopub.execute_input":"2025-11-01T10:04:55.965009Z","iopub.status.idle":"2025-11-01T10:22:56.118856Z","shell.execute_reply.started":"2025-11-01T10:04:55.964991Z","shell.execute_reply":"2025-11-01T10:22:56.118166Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-11-01 10:06:50.849613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761991611.049698      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761991611.105289      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6858a7a0fa41ae8efb41643d017758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sst2/train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcae9521e0f9446e950ae4651dd6d882"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sst2/validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88dcbf47e1824dc4936826c60d0f140f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sst2/test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf090c0a4704c5499e8d55304ea434e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54ea59d015141f1b72425c8ebe9b165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc58103b4de483c8c2250f0087251ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dca41bb3fd84f34862b3a44fcc8933c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116f40b7f48f4265a9ebc0a2457ec186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f59046922804b93ab181b3484f40146"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11cd9822c1445f5a072896835b1c24d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2176e446a33544578714b914099926a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f4f7bfb93742bea5c38250d2c3386c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6825571e8954441882fec049eba31547"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b3bafb14caa46f782bd2a6488bb5bfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b64ffd692484dfe87523a80a61d71b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c20a519cae6b4e2ba8d388d0bebc4e64"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/kaggle/working/wandb/offline-run-20251101_100738-myhi8xtw</code>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_37/2653458283.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6315' max='6315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6315/6315 15:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.152400</td>\n      <td>0.215355</td>\n      <td>0.928899</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.095900</td>\n      <td>0.273911</td>\n      <td>0.915138</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.068000</td>\n      <td>0.275303</td>\n      <td>0.932339</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Validation: {'eval_loss': 0.2753034234046936, 'eval_accuracy': 0.9323394495412844, 'eval_runtime': 1.3989, 'eval_samples_per_second': 623.343, 'eval_steps_per_second': 10.008, 'epoch': 3.0}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Saved best model to: /kaggle/working/glue_ft/best_model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▁██</td></tr><tr><td>eval/loss</td><td>▁███</td></tr><tr><td>eval/runtime</td><td>▁▁▄█</td></tr><tr><td>eval/samples_per_second</td><td>██▅▁</td></tr><tr><td>eval/steps_per_second</td><td>██▅▁</td></tr><tr><td>final/global_step</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁█</td></tr><tr><td>test/samples_per_second</td><td>█▁</td></tr><tr><td>+12</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.93234</td></tr><tr><td>eval/loss</td><td>0.2753</td></tr><tr><td>eval/runtime</td><td>1.3989</td></tr><tr><td>eval/samples_per_second</td><td>623.343</td></tr><tr><td>eval/steps_per_second</td><td>10.008</td></tr><tr><td>final/global_step</td><td>6315</td></tr><tr><td>test/accuracy</td><td>0.93234</td></tr><tr><td>test/loss</td><td>0.2753</td></tr><tr><td>test/runtime</td><td>2.8434</td></tr><tr><td>test/samples_per_second</td><td>640.433</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"You can sync this run to the cloud by running:<br><code>wandb sync /kaggle/working/wandb/offline-run-20251101_100738-myhi8xtw<code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/offline-run-20251101_100738-myhi8xtw/logs</code>"},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\nQuick how to on Kaggle\\n\\n1. Keep Internet and GPU on.\\n2. To use W&B, add your key via Kaggle Secrets: Workspace > Add-ons > Secrets > Create new secret with key WANDB_API_KEY. Or set it in an env var.\\n3. Run this cell. Default model is bert-base-uncased with AutoModelForSequenceClassification.\\n4. Artifacts:\\n   - best model at /kaggle/working/glue_ft/best_model\\n   - JSON metrics in the output dir\\n   - optional logits .npy files for validation and test\\n5. Later evaluation:\\n\\nfrom Kaggle_HF_Trainer_GLUE_full_finetune import load_for_eval\\nload_for_eval(\"/kaggle/working/glue_ft/best_model\", \"sst2\")\\n\\nW&B tips\\n- Set CFG.wandb_enable = True to log. Set False to disable.\\n- Project and entity are configurable: CFG.wandb_project, CFG.wandb_entity.\\n- If no key is found and offline fallback is True, the run will log locally in offline mode.\\n\\nNotes\\n- This is full finetuning. Nothing is frozen.\\n- For STS-B, config.problem_type=\"regression\" is set and MSE is used automatically.\\n- To switch models, set CFG.model_name (for example, roberta-base).\\n'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}