# TODO List


## 1. Slides
- [x] LoRA methodology
- [ ] QLoRA methodology
- [ ] Discussion

## 2. Experiments
### 2.1 Full finetuning

---
roberta-base:  [version 2](https://www.kaggle.com/code/toanltv/ft-peft)

---

roberta-large: [version 2](https://www.kaggle.com/code/nlp02aio/ft-peft), [version 1](https://www.kaggle.com/code/hoangggv/ft-peft)


---

microsoft/deberta-v3-base: [version 1](https://www.kaggle.com/code/hhhhhvvvvvv/ft-peft) [version 1](https://www.kaggle.com/code/lemmnguyen/ft-peft)

---

### 2.2 LoRA
#### 2.2.1 LoRA: q, k, v


#### 2.2.2 LoRA: q, k, v, d (attention) 


### 2.3 QLoRA


